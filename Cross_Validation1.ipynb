{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a45c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8d8643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"D:\\Pandas dataset\\heart (1).csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4faea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feac9c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=2, random_state=10, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=2,random_state=10, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2579d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    2    3    4    5    8    9   13   14   15   17   18   19   23\n",
      "   25   26   32   36   38   40   41   42   44   46   48   49   50   51\n",
      "   53   54   55   58   59   61   62   63   66   67   70   71   73   74\n",
      "   77   79   81   82   83   86   89   90   93   95   98  101  103  106\n",
      "  107  111  112  113  117  118  119  122  123  127  128  129  134  135\n",
      "  136  137  144  145  146  148  149  150  154  156  158  160  162  165\n",
      "  168  178  180  182  185  186  187  189  198  200  201  204  205  206\n",
      "  207  208  209  210  212  213  214  216  219  221  226  227  232  234\n",
      "  239  241  243  246  247  251  255  256  258  263  265  266  267  268\n",
      "  269  270  275  279  281  283  286  288  289  290  291  296  297  301\n",
      "  306  308  310  312  313  314  316  319  320  321  324  327  328  330\n",
      "  331  332  333  336  337  338  340  342  343  344  346  347  348  350\n",
      "  352  355  356  357  359  360  362  363  364  365  366  368  369  371\n",
      "  373  376  377  380  382  385  388  390  391  393  394  395  397  400\n",
      "  401  404  405  406  409  412  416  420  421  422  423  424  427  430\n",
      "  432  433  434  435  436  439  446  451  453  454  455  458  459  460\n",
      "  461  464  465  466  468  469  470  471  472  474  476  477  478  480\n",
      "  481  488  490  493  494  496  498  502  503  505  506  509  512  515\n",
      "  516  517  521  522  523  526  527  528  530  532  533  534  535  540\n",
      "  541  542  543  545  549  550  551  552  553  554  555  556  557  559\n",
      "  560  561  563  564  565  570  574  575  578  579  583  586  587  588\n",
      "  589  591  595  597  599  602  605  606  607  608  612  613  615  616\n",
      "  617  619  624  627  630  632  636  639  640  641  644  645  647  648\n",
      "  650  652  653  654  655  656  657  660  661  662  665  668  670  671\n",
      "  674  675  677  678  680  681  683  689  690  691  700  701  703  708\n",
      "  710  711  713  714  715  716  717  718  720  721  722  724  725  727\n",
      "  732  733  736  738  740  741  745  746  747  749  753  755  756  758\n",
      "  759  760  762  763  766  771  777  778  779  780  782  783  784  785\n",
      "  786  787  793  794  796  797  798  799  801  802  803  804  805  813\n",
      "  814  815  816  817  818  824  825  828  830  834  835  842  843  847\n",
      "  848  849  854  856  860  864  865  866  867  868  870  871  874  876\n",
      "  877  881  883  890  891  893  895  897  898  899  901  903  904  905\n",
      "  907  909  911  913  915  916  918  919  922  923  925  926  927  929\n",
      "  933  934  935  936  937  938  942  944  947  949  951  954  955  956\n",
      "  957  958  959  960  965  968  972  973  974  975  979  981  984  985\n",
      "  986  988  989  990  993  996  998 1000 1001 1002 1003 1009 1011 1012\n",
      " 1013 1014 1016 1017 1019 1020 1021 1023] TEST: [   1    6    7   10   11   12   16   20   21   22   24   27   28   29\n",
      "   30   31   33   34   35   37   39   43   45   47   52   56   57   60\n",
      "   64   65   68   69   72   75   76   78   80   84   85   87   88   91\n",
      "   92   94   96   97   99  100  102  104  105  108  109  110  114  115\n",
      "  116  120  121  124  125  126  130  131  132  133  138  139  140  141\n",
      "  142  143  147  151  152  153  155  157  159  161  163  164  166  167\n",
      "  169  170  171  172  173  174  175  176  177  179  181  183  184  188\n",
      "  190  191  192  193  194  195  196  197  199  202  203  211  215  217\n",
      "  218  220  222  223  224  225  228  229  230  231  233  235  236  237\n",
      "  238  240  242  244  245  248  249  250  252  253  254  257  259  260\n",
      "  261  262  264  271  272  273  274  276  277  278  280  282  284  285\n",
      "  287  292  293  294  295  298  299  300  302  303  304  305  307  309\n",
      "  311  315  317  318  322  323  325  326  329  334  335  339  341  345\n",
      "  349  351  353  354  358  361  367  370  372  374  375  378  379  381\n",
      "  383  384  386  387  389  392  396  398  399  402  403  407  408  410\n",
      "  411  413  414  415  417  418  419  425  426  428  429  431  437  438\n",
      "  440  441  442  443  444  445  447  448  449  450  452  456  457  462\n",
      "  463  467  473  475  479  482  483  484  485  486  487  489  491  492\n",
      "  495  497  499  500  501  504  507  508  510  511  513  514  518  519\n",
      "  520  524  525  529  531  536  537  538  539  544  546  547  548  558\n",
      "  562  566  567  568  569  571  572  573  576  577  580  581  582  584\n",
      "  585  590  592  593  594  596  598  600  601  603  604  609  610  611\n",
      "  614  618  620  621  622  623  625  626  628  629  631  633  634  635\n",
      "  637  638  642  643  646  649  651  658  659  663  664  666  667  669\n",
      "  672  673  676  679  682  684  685  686  687  688  692  693  694  695\n",
      "  696  697  698  699  702  704  705  706  707  709  712  719  723  726\n",
      "  728  729  730  731  734  735  737  739  742  743  744  748  750  751\n",
      "  752  754  757  761  764  765  767  768  769  770  772  773  774  775\n",
      "  776  781  788  789  790  791  792  795  800  806  807  808  809  810\n",
      "  811  812  819  820  821  822  823  826  827  829  831  832  833  836\n",
      "  837  838  839  840  841  844  845  846  850  851  852  853  855  857\n",
      "  858  859  861  862  863  869  872  873  875  878  879  880  882  884\n",
      "  885  886  887  888  889  892  894  896  900  902  906  908  910  912\n",
      "  914  917  920  921  924  928  930  931  932  939  940  941  943  945\n",
      "  946  948  950  952  953  961  962  963  964  966  967  969  970  971\n",
      "  976  977  978  980  982  983  987  991  992  994  995  997  999 1004\n",
      " 1005 1006 1007 1008 1010 1015 1018 1022 1024]\n",
      "TRAIN: [   1    6    7   10   11   12   16   20   21   22   24   27   28   29\n",
      "   30   31   33   34   35   37   39   43   45   47   52   56   57   60\n",
      "   64   65   68   69   72   75   76   78   80   84   85   87   88   91\n",
      "   92   94   96   97   99  100  102  104  105  108  109  110  114  115\n",
      "  116  120  121  124  125  126  130  131  132  133  138  139  140  141\n",
      "  142  143  147  151  152  153  155  157  159  161  163  164  166  167\n",
      "  169  170  171  172  173  174  175  176  177  179  181  183  184  188\n",
      "  190  191  192  193  194  195  196  197  199  202  203  211  215  217\n",
      "  218  220  222  223  224  225  228  229  230  231  233  235  236  237\n",
      "  238  240  242  244  245  248  249  250  252  253  254  257  259  260\n",
      "  261  262  264  271  272  273  274  276  277  278  280  282  284  285\n",
      "  287  292  293  294  295  298  299  300  302  303  304  305  307  309\n",
      "  311  315  317  318  322  323  325  326  329  334  335  339  341  345\n",
      "  349  351  353  354  358  361  367  370  372  374  375  378  379  381\n",
      "  383  384  386  387  389  392  396  398  399  402  403  407  408  410\n",
      "  411  413  414  415  417  418  419  425  426  428  429  431  437  438\n",
      "  440  441  442  443  444  445  447  448  449  450  452  456  457  462\n",
      "  463  467  473  475  479  482  483  484  485  486  487  489  491  492\n",
      "  495  497  499  500  501  504  507  508  510  511  513  514  518  519\n",
      "  520  524  525  529  531  536  537  538  539  544  546  547  548  558\n",
      "  562  566  567  568  569  571  572  573  576  577  580  581  582  584\n",
      "  585  590  592  593  594  596  598  600  601  603  604  609  610  611\n",
      "  614  618  620  621  622  623  625  626  628  629  631  633  634  635\n",
      "  637  638  642  643  646  649  651  658  659  663  664  666  667  669\n",
      "  672  673  676  679  682  684  685  686  687  688  692  693  694  695\n",
      "  696  697  698  699  702  704  705  706  707  709  712  719  723  726\n",
      "  728  729  730  731  734  735  737  739  742  743  744  748  750  751\n",
      "  752  754  757  761  764  765  767  768  769  770  772  773  774  775\n",
      "  776  781  788  789  790  791  792  795  800  806  807  808  809  810\n",
      "  811  812  819  820  821  822  823  826  827  829  831  832  833  836\n",
      "  837  838  839  840  841  844  845  846  850  851  852  853  855  857\n",
      "  858  859  861  862  863  869  872  873  875  878  879  880  882  884\n",
      "  885  886  887  888  889  892  894  896  900  902  906  908  910  912\n",
      "  914  917  920  921  924  928  930  931  932  939  940  941  943  945\n",
      "  946  948  950  952  953  961  962  963  964  966  967  969  970  971\n",
      "  976  977  978  980  982  983  987  991  992  994  995  997  999 1004\n",
      " 1005 1006 1007 1008 1010 1015 1018 1022 1024] TEST: [   0    2    3    4    5    8    9   13   14   15   17   18   19   23\n",
      "   25   26   32   36   38   40   41   42   44   46   48   49   50   51\n",
      "   53   54   55   58   59   61   62   63   66   67   70   71   73   74\n",
      "   77   79   81   82   83   86   89   90   93   95   98  101  103  106\n",
      "  107  111  112  113  117  118  119  122  123  127  128  129  134  135\n",
      "  136  137  144  145  146  148  149  150  154  156  158  160  162  165\n",
      "  168  178  180  182  185  186  187  189  198  200  201  204  205  206\n",
      "  207  208  209  210  212  213  214  216  219  221  226  227  232  234\n",
      "  239  241  243  246  247  251  255  256  258  263  265  266  267  268\n",
      "  269  270  275  279  281  283  286  288  289  290  291  296  297  301\n",
      "  306  308  310  312  313  314  316  319  320  321  324  327  328  330\n",
      "  331  332  333  336  337  338  340  342  343  344  346  347  348  350\n",
      "  352  355  356  357  359  360  362  363  364  365  366  368  369  371\n",
      "  373  376  377  380  382  385  388  390  391  393  394  395  397  400\n",
      "  401  404  405  406  409  412  416  420  421  422  423  424  427  430\n",
      "  432  433  434  435  436  439  446  451  453  454  455  458  459  460\n",
      "  461  464  465  466  468  469  470  471  472  474  476  477  478  480\n",
      "  481  488  490  493  494  496  498  502  503  505  506  509  512  515\n",
      "  516  517  521  522  523  526  527  528  530  532  533  534  535  540\n",
      "  541  542  543  545  549  550  551  552  553  554  555  556  557  559\n",
      "  560  561  563  564  565  570  574  575  578  579  583  586  587  588\n",
      "  589  591  595  597  599  602  605  606  607  608  612  613  615  616\n",
      "  617  619  624  627  630  632  636  639  640  641  644  645  647  648\n",
      "  650  652  653  654  655  656  657  660  661  662  665  668  670  671\n",
      "  674  675  677  678  680  681  683  689  690  691  700  701  703  708\n",
      "  710  711  713  714  715  716  717  718  720  721  722  724  725  727\n",
      "  732  733  736  738  740  741  745  746  747  749  753  755  756  758\n",
      "  759  760  762  763  766  771  777  778  779  780  782  783  784  785\n",
      "  786  787  793  794  796  797  798  799  801  802  803  804  805  813\n",
      "  814  815  816  817  818  824  825  828  830  834  835  842  843  847\n",
      "  848  849  854  856  860  864  865  866  867  868  870  871  874  876\n",
      "  877  881  883  890  891  893  895  897  898  899  901  903  904  905\n",
      "  907  909  911  913  915  916  918  919  922  923  925  926  927  929\n",
      "  933  934  935  936  937  938  942  944  947  949  951  954  955  956\n",
      "  957  958  959  960  965  968  972  973  974  975  979  981  984  985\n",
      "  986  988  989  990  993  996  998 1000 1001 1002 1003 1009 1011 1012\n",
      " 1013 1014 1016 1017 1019 1020 1021 1023]\n"
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1786f8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83268482 0.8671875 ]\n",
      "84.9936162451362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l1=LogisticRegression()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(l1, x_train,y_train, cv=kf)\n",
    "print(scores)\n",
    "print(np.mean(scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4cd3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1\n",
      " 0 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0\n",
      " 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1\n",
      " 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1\n",
      " 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
      " 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred=cross_val_predict(l1,x_test,y_test,cv=kf)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f94b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
